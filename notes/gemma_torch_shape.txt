
===== SHAPES OF GEMMA MODEL =====

For google/gemma-3-4b-pt:

Gemma3TextModel(
  (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)
  (layers): ModuleList(
    (0-33): 34 x Gemma3DecoderLayer(
      (self_attn): Gemma3Attention(
        (q_proj): Linear(in_features=2560, out_features=2048, bias=False)
        (k_proj): Linear(in_features=2560, out_features=1024, bias=False)
        (v_proj): Linear(in_features=2560, out_features=1024, bias=False)
        (o_proj): Linear(in_features=2048, out_features=2560, bias=False)
        (q_norm): Gemma3RMSNorm((256,), eps=1e-06)
        (k_norm): Gemma3RMSNorm((256,), eps=1e-06)
      )
      (mlp): Gemma3MLP(
        (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)
        (up_proj): Linear(in_features=2560, out_features=10240, bias=False)
        (down_proj): Linear(in_features=10240, out_features=2560, bias=False)
        (act_fn): GELUTanh()
      )
      (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)
      (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)
      (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)
      (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)
    )
  )
  (norm): Gemma3RMSNorm((2560,), eps=1e-06)
  (rotary_emb): Gemma3RotaryEmbedding()
)
